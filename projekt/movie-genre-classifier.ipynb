{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zu welchem Genre geh√∂rt das Filmposter\n",
    "\n",
    "Ablauf:\n",
    "\n",
    "1. Importieren von allen Bibliotheken\n",
    "2. Einlesen der csv Datei\n",
    "3. Datenbereinigung\n",
    "4. Herunterladen der Bilder\n",
    "5. Input Pipeline erstellen\n",
    "6. Ki Model bauen\n",
    "7. Model trainieren und evaluieren\n",
    "8. Exportieren & sichern des Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style as style\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import shutil\n",
    "import multiprocessing\n",
    "import urllib.error\n",
    "import urllib.request\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "from time import time\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "from keras.preprocessing import image\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.calibration import calibration_curve\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from utils import *\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Laden der Daten"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "   imdbId                           Imdb Link  \\\n0  114709  http://www.imdb.com/title/tt114709   \n1  113497  http://www.imdb.com/title/tt113497   \n2  113228  http://www.imdb.com/title/tt113228   \n3  114885  http://www.imdb.com/title/tt114885   \n4  113041  http://www.imdb.com/title/tt113041   \n\n                                Title  IMDB Score                       Genre  \\\n0                    Toy Story (1995)         8.3  Animation|Adventure|Comedy   \n1                      Jumanji (1995)         6.9     Action|Adventure|Family   \n2             Grumpier Old Men (1995)         6.6              Comedy|Romance   \n3            Waiting to Exhale (1995)         5.7        Comedy|Drama|Romance   \n4  Father of the Bride Part II (1995)         5.9       Comedy|Family|Romance   \n\n                                              Poster  \n0  https://images-na.ssl-images-amazon.com/images...  \n1  https://images-na.ssl-images-amazon.com/images...  \n2  https://images-na.ssl-images-amazon.com/images...  \n3  https://images-na.ssl-images-amazon.com/images...  \n4  https://images-na.ssl-images-amazon.com/images...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>imdbId</th>\n      <th>Imdb Link</th>\n      <th>Title</th>\n      <th>IMDB Score</th>\n      <th>Genre</th>\n      <th>Poster</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>114709</td>\n      <td>http://www.imdb.com/title/tt114709</td>\n      <td>Toy Story (1995)</td>\n      <td>8.3</td>\n      <td>Animation|Adventure|Comedy</td>\n      <td>https://images-na.ssl-images-amazon.com/images...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>113497</td>\n      <td>http://www.imdb.com/title/tt113497</td>\n      <td>Jumanji (1995)</td>\n      <td>6.9</td>\n      <td>Action|Adventure|Family</td>\n      <td>https://images-na.ssl-images-amazon.com/images...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>113228</td>\n      <td>http://www.imdb.com/title/tt113228</td>\n      <td>Grumpier Old Men (1995)</td>\n      <td>6.6</td>\n      <td>Comedy|Romance</td>\n      <td>https://images-na.ssl-images-amazon.com/images...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>114885</td>\n      <td>http://www.imdb.com/title/tt114885</td>\n      <td>Waiting to Exhale (1995)</td>\n      <td>5.7</td>\n      <td>Comedy|Drama|Romance</td>\n      <td>https://images-na.ssl-images-amazon.com/images...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>113041</td>\n      <td>http://www.imdb.com/title/tt113041</td>\n      <td>Father of the Bride Part II (1995)</td>\n      <td>5.9</td>\n      <td>Comedy|Family|Romance</td>\n      <td>https://images-na.ssl-images-amazon.com/images...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_data = pd.read_csv(\"./data/MovieGenre.csv\",\n",
    "                          sep=\",\", encoding='unicode_escape', index_col=None)\n",
    "movie_data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Datenbereinigung"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# Entfernen von Null Werten\n",
    "movie_data.dropna(subset=['imdbId', 'Genre', 'Poster'], inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Herunterladen der Daten (Parallel)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created new directory './data/movie-posters'\n",
      "\n",
      "Downloading...\n",
      "\n",
      "Download in parallel mode took 1034 seconds.\n",
      "Success: 36337\n",
      "Errors: 2926\n"
     ]
    }
   ],
   "source": [
    "def download_parallel(movies, image_dir):\n",
    "    # Create list of filenames\n",
    "    filenames = movies['imdbId'].apply(lambda imbdId : os.path.join(image_dir, str(imbdId)+'.jpg'))\n",
    "    # Create list of image urls\n",
    "    urls = movies['Poster']\n",
    "\n",
    "    # Create destination directory\n",
    "    if os.path.exists(image_dir):\n",
    "        print(\"Directory '{}' already exists and will be deleted.\".format(image_dir))\n",
    "        shutil.rmtree(image_dir)\n",
    "    print(\"Created new directory '{}'\".format(image_dir))\n",
    "    os.makedirs(image_dir)\n",
    "\n",
    "    # Define function to download one single image\n",
    "    def download_image(url, filename):\n",
    "        try:\n",
    "            urllib.request.urlretrieve(url, filename)\n",
    "            return 0\n",
    "        except:\n",
    "            return os.path.basename(filename).split('.')[0]\n",
    "\n",
    "    # Download images in parallel\n",
    "    start = time()\n",
    "    print(\"\\nDownloading...\")\n",
    "    num_cores = multiprocessing.cpu_count()\n",
    "    ko_list = Parallel(n_jobs=num_cores)(delayed(download_image)(u, f) for f, u in zip(filenames, urls))\n",
    "\n",
    "    print(\"\\nDownload in parallel mode took %d seconds.\" %(time()-start))\n",
    "    print(\"Success:\", len([i for i in ko_list if i==0]))\n",
    "    print(\"Errors:\", len([i for i in ko_list if i!=0]))\n",
    "\n",
    "    # Remove not downloaded posters from the dataframe\n",
    "    ko_index = movies[movies['imdbId'].isin(ko_list)].index\n",
    "    movies = movies.drop(ko_index)\n",
    "\n",
    "    return movies\n",
    "\n",
    "\n",
    "destination = './data/movie-posters'\n",
    "movie_data = download_parallel(movie_data, destination)\n",
    "\n",
    "munge_dir = \"./data\"\n",
    "if not os.path.exists(munge_dir):\n",
    "    os.makedirs(munge_dir)\n",
    "movie_data.to_csv(os.path.join(munge_dir, \"movies.csv\"), index=False)\n",
    "\n",
    "\n",
    "movie_data = pd.read_csv(\"./munge/movies.csv\")\n",
    "print(\"Number of movie posters in last download: {}\\n\".format(len(movie_data)))\n",
    "movie_data.head(3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Input Pipeline erstellen"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(movie_data['imdbId'], movie_data['Genre'], test_size=0.2, random_state=44)\n",
    "print(\"Number of posters for training: \", len(X_train))\n",
    "print(\"Number of posters for validation: \", len(X_val))\n",
    "\n",
    "# we need files instead of imdbIds\n",
    "X_train = [os.path.join('./data/movie_poster/images', str(f)+'.jpg') for f in X_train]\n",
    "X_val = [os.path.join('./data/movie_poster/images', str(f)+'.jpg') for f in X_val]\n",
    "print(X_train[:3])\n",
    "print(X_val[:3])\n",
    "\n",
    "y_train = list(y_train)\n",
    "y_val = list(y_val)\n",
    "print(y_train[:3])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Beispiel Bilder"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "nobs = 8 # Maximum number of images to display\n",
    "ncols = 4 # Number of columns in display\n",
    "nrows = nobs//ncols # Number of rows in display\n",
    "\n",
    "style.use(\"default\")\n",
    "plt.figure(figsize=(12,4*nrows))\n",
    "for i in range(nrows*ncols):\n",
    "    ax = plt.subplot(nrows, ncols, i+1)\n",
    "    plt.imshow(Image.open(X_train[i]))\n",
    "    plt.title(y_train[i], size=10)\n",
    "    plt.axis('off')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    " Label encoding"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Fit the multi-label binarizer on the training set\n",
    "print(\"Labels:\")\n",
    "mlb = MultiLabelBinarizer()\n",
    "mlb.fit(y_train)\n",
    "\n",
    "# Loop over all labels and show them\n",
    "N_LABELS = len(mlb.classes_)\n",
    "for (i, label) in enumerate(mlb.classes_):\n",
    "    print(\"{}. {}\".format(i, label))\n",
    "\n",
    "# transform the targets of the training and test sets\n",
    "y_train_bin = mlb.transform(y_train)\n",
    "y_val_bin = mlb.transform(y_val)\n",
    "\n",
    "# Print example of movie posters and their binary targets\n",
    "for i in range(3):\n",
    "    print(X_train[i], y_train_bin[i])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Pipeline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "IMG_SIZE = 224 # Height and Width of an Image\n",
    "CHANNELS = 3 # 3 Stands for RGB\n",
    "\n",
    "BATCH_SIZE = 256 # Big enough to measure an F1-score\n",
    "SHUFFLE_BUFFER_SIZE = 1024 # Shuffle the training data by a chunck of 1024 observations\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE # Adapt preprocessing and prefetching dynamically\n",
    "\n",
    "\n",
    "def parse_function(filename, label):\n",
    "    # Read an image from a file\n",
    "    image_string = tf.io.read_file(filename)\n",
    "    # Decode it into a dense vector\n",
    "    image_decoded = tf.image.decode_jpeg(image_string, channels=CHANNELS)\n",
    "    # Resize it to fixed shape\n",
    "    image_resized = tf.image.resize(image_decoded, [IMG_SIZE, IMG_SIZE])\n",
    "    # Normalize it from [0, 255] to [0.0, 1.0]\n",
    "    image_normalized = image_resized / 255.0\n",
    "    return image_normalized, label\n",
    "\n",
    "def create_dataset(filenames, labels, is_training=True):\n",
    "    # Create a first dataset of file paths and labels\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\n",
    "    # Parse and preprocess observations in parallel\n",
    "    dataset = dataset.map(parse_function, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "    if is_training == True:\n",
    "        # This is a small dataset, only load it once, and keep it in memory.\n",
    "        dataset = dataset.cache()\n",
    "        # Shuffle the data each buffer size\n",
    "        dataset = dataset.shuffle(buffer_size=SHUFFLE_BUFFER_SIZE)\n",
    "\n",
    "    # Batch the data for multiple steps\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    # Fetch batches in the background while the model is training.\n",
    "    dataset = dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "train_ds = create_dataset(X_train, y_train_bin)\n",
    "val_ds = create_dataset(X_val, y_val_bin)\n",
    "\n",
    "for f, l in train_ds.take(1):\n",
    "    print(\"Shape of features array:\", f.numpy().shape)\n",
    "    print(\"Shape of labels array:\", l.numpy().shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model bauen"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    # TODO:########################################################\n",
    "    layers.Dense(1024, activation='relu', name='hidden_layer'),\n",
    "    layers.Dense(N_LABELS, activation='sigmoid', name='output')\n",
    "])\n",
    "\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e535dff822bbfad958fc501bc24b0904ebfa4afeaf590caddba64e3bf49731e3"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}