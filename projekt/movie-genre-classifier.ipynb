{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Inhaltsbasierte Suche in Bildern</h1>\n",
    "<p style=\"font-size:18px\">\n",
    "Entwicklung eines Programms, welches anhand eines Filmposter die dazugehörigen Genres ermittelt.\n",
    "</p>\n",
    "<div style=\" display: flex; \n",
    "    justify-content: center; \n",
    "    align-items: center;\">\n",
    "<img src=\"./vortrag/Aufgabe.png\" alt=\"Aufagbe\" width=\"300\" height=\"400\"  title=\"\"/>\n",
    "</div>\n",
    "\n",
    "<h2> Inhaltsverzeichnis </h2>\n",
    "<div style=\"font-size:18px\">\n",
    "    1. Motivation\n",
    "    <br>\n",
    "    2. Einordnung in das Thema Machine Learning \n",
    "    <br>\n",
    "    3. Preprocessing\n",
    "    <br>\n",
    "    4. neuronale Netze \n",
    "    <br>\n",
    "    5. Demo\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Motivation </h1>\n",
    "\n",
    "<div style=\"font-size:18px;\">\n",
    "    1. Biologie \n",
    "        -  Erkennung von Tierarten / Erkennung von Zelltypen\n",
    "    <br>\n",
    "    2. Werbung - Kommen Werbeplakaten bei Kunden an \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Einordnung in das Thema Maschine Learning</h1>\n",
    "<div style=\"font-size:18px\">\n",
    "Um Bilder zu klassifizieren werden neuronale Netze benutzt. Diese sind aus der Biologie bekannt. Es gibt verschiedenen <i>Neuronen</i> die miteinander <i>vernetzt</i> sind. Wie in der Biologie werden auch hier Neuronen aktiviert oder nicht, dies ist abhängig von den Werten die an das Neuron gesendet werden\n",
    "</div>\n",
    "<div style=\" display: flex; \n",
    "    justify-content: center; \n",
    "    align-items: center;\">\n",
    "<img src=\"./vortrag/modell-architektur.png\" alt=\"Aufagbe\" width=\"650\" height=\"300\"  title=\"\"/>\n",
    "</div>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<div style=\" display: flex; \n",
    "    justify-content: center; \n",
    "    align-items: center;\">\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Vorgehen </h1>\n",
    "<div style=\"font-size:18px\">\n",
    "    1. Importieren der benötigen Bibliotheken\n",
    "    <br>\n",
    "    2. Laden der Daten\n",
    "    <br>\n",
    "    3. Datenbereinigung\n",
    "    <br>\n",
    "    4. Datenvorbereitung\n",
    "    <br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Importieren der benötigen Bibliotheken</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.0\n",
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style as style\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import shutil\n",
    "import multiprocessing\n",
    "import urllib.error\n",
    "import urllib.request\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "from time import time\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.calibration import calibration_curve\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "print(tf.__version__)\n",
    "print(tf.config.list_physical_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h2> Laden der CSV Datei </h2>\n",
    "<p style=\"font-size:18px\">\n",
    "Die Daten bekommen wir von Kaggel. Kaggel bietet verschiedene CSV Dateien - zu allmöglichen Themen - , über die die Daten runtergeladen werden können an. \n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "movie_data = pd.read_csv(\"./data/MovieGenre.csv\",\n",
    "                          sep=\",\", encoding='unicode_escape', index_col=None)\n",
    "movie_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Erste Datenbereinigung </h2>\n",
    "<p style=\"font-size:18px\">\n",
    "Löschen der Zeilen die einen Null Wert enthalten, da wir mit diesen Zeilen nichts anfangen können.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Entfernen von Null Werten\n",
    "movie_data.dropna(subset=['imdbId', 'Genre', 'Poster'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Herunterladen der Film Poster (parallel)</h2>\n",
    "<p style=\"font-size:18px\">\n",
    "Die Filmposter, die in der CSV Datei angegeben sind werden heruntergeladen, um dies zu beschleunigen werden die Bilder parallel heruntergeladen.\n",
    "</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def download_parallel(movies, image_dir):\n",
    "    # Create list of filenames\n",
    "    filenames = movies['imdbId'].apply(lambda imbdId : os.path.join(image_dir, str(imbdId)+'.jpg'))\n",
    "    # Create list of image urls\n",
    "    urls = movies['Poster']\n",
    "\n",
    "    # Create destination directory\n",
    "    if os.path.exists(image_dir):\n",
    "        print(\"Directory '{}' already exists and will be deleted.\".format(image_dir))\n",
    "        shutil.rmtree(image_dir)\n",
    "    print(\"Created new directory '{}'\".format(image_dir))\n",
    "    os.makedirs(image_dir)\n",
    "\n",
    "    # Define function to download one single image\n",
    "    def download_image(url, filename):\n",
    "        try:\n",
    "            urllib.request.urlretrieve(url, filename)\n",
    "            return 0\n",
    "        except:\n",
    "            return os.path.basename(filename).split('.')[0]\n",
    "\n",
    "    # Download images in parallel\n",
    "    start = time()\n",
    "    print(\"\\nDownloading...\")\n",
    "    num_cores = multiprocessing.cpu_count()\n",
    "    ko_list = Parallel(n_jobs=num_cores)(delayed(download_image)(u, f) for f, u in zip(filenames, urls))\n",
    "\n",
    "    print(\"\\nDownload in parallel mode took %d seconds.\" %(time()-start))\n",
    "    print(\"Success:\", len([i for i in ko_list if i==0]))\n",
    "    print(\"Errors:\", len([i for i in ko_list if i!=0]))\n",
    "\n",
    "    # Remove not downloaded posters from the dataframe\n",
    "    print(\"length of Movies before removing errors: \" + str(len(movies)))\n",
    "    imdbIdToBeRemoved = []\n",
    "    for item in ko_list:\n",
    "        if(item !=0):\n",
    "            imdbIdToBeRemoved.append(item)\n",
    "    movies= movies[~ movies[\"imdbId\"].astype(str).isin(imdbIdToBeRemoved)]\n",
    "    print(\"length of Movies after removing errors: \" + str(len(movies)))\n",
    "\n",
    "    return movies\n",
    "\n",
    "\n",
    "destination = './data/movie-posters'\n",
    "movie_data = download_parallel(movie_data, destination)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Erstellen einer neuen CSV Datei</h2>\n",
    "<p style=\"font-size:18px\">\n",
    "Die CSV Datei enthält nur angaben zu den Bilder, die heruntergeladen wurden\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_dir = \"./data\"\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "movie_data.to_csv(os.path.join(data_dir, \"movies.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Zweite Datenbereinigung</h2>\n",
    "<p style=\"font-size:18px\">\n",
    "Jetzt wo wir wissen welche Bilder wir haben, können wir eine zweite Datenbereitung machen und die Daten fürs Training vorbereiten <br>\n",
    "<br>\n",
    " 1. Wir zählen, wie oft ein Label vorkommt<br>\n",
    " 2. Speichern alle Labels die weniger als 1000 mal vorkommen in einer Liste<br>\n",
    " 3. Entfernen aller Labels die mit einem der Labels in der zuvor erstellten Liste übereinstimmen<br>\n",
    " 4. Entfernen von einigen Dramen, da wir von diesen viel mehr Testdaten haben als von anderen<br>\n",
    " </p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size:18px\">Ermitteln der Genrehäufigkeiten</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "movie_data = pd.read_csv(\"./data/movies.csv\")\n",
    "\n",
    "label_freq = movie_data['Genre'].apply(lambda s: str(s).split(\n",
    "    '|')).explode().value_counts().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size:18px\">Erstellung einer Grafik der Genrehäufigkeiten</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style.use(\"fivethirtyeight\")\n",
    "plt.figure(figsize=(12,10))\n",
    "sns.barplot(y=label_freq.index.values, x=label_freq, order=label_freq.index)\n",
    "plt.title(\"Label frequency\", fontsize=14)\n",
    "plt.xlabel(\"\")\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size:18px\">Entfernen von Filme mit keinem Genre und Filme aus dem Genre \"Drama\" (maximal 7000). <br> Dies hat den Hintergrund, damit nicht zu viele Daten eines Genres existieren</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rare = list(label_freq[label_freq < 1000].index)\n",
    "display(rare)\n",
    "\n",
    "print(f\"Number of movie posters in last download: {len(movie_data)}\")\n",
    "movie_data['Genre'] = movie_data['Genre'].apply(\n",
    "    lambda s: [l for l in str(s).split('|') if l not in rare])\n",
    "\n",
    "empty_genres = movie_data[\"Genre\"].apply(\n",
    "    lambda x: not x)\n",
    "\n",
    "movie_data = movie_data.drop(movie_data[empty_genres].index)\n",
    "print(\n",
    "    f\"Number of movie posters after deleting empty genre movies: {len(movie_data)}\")\n",
    "DRAMA_REMOVE_COUNT = 7000\n",
    "only_drama = movie_data[\"Genre\"].apply(\n",
    "    lambda x: all(g == \"Drama\" for g in x))\n",
    "only_drama = only_drama[only_drama == True].iloc[0:DRAMA_REMOVE_COUNT]\n",
    "movie_data = movie_data.drop(only_drama.index)\n",
    "print(\n",
    "    f\"Number of movie posters after deleting {len(only_drama)} only drama movies: {len(movie_data)}\")\n",
    "\n",
    "movie_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h2> Daten aufteilen in Trainings- und Validierungsdaten.</h2>\n",
    "<p style=\"font-size:20px\">\n",
    "    Die Filmposter werden aufgeteilt in 80% Trainingsdaten und 20% Validierungsdaten\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(movie_data['imdbId'], movie_data['Genre'], test_size=0.2, random_state=44)\n",
    "print(\"Number of posters for training: \", len(X_train))\n",
    "print(\"Number of posters for validation: \", len(X_val))\n",
    "\n",
    "# we need files instead of imdbIds\n",
    "X_train = [os.path.join('./data/movie-posters/', str(f)+'.jpg') for f in X_train]\n",
    "X_val = [os.path.join('./data/movie-posters/', str(f)+'.jpg') for f in X_val]\n",
    "print(X_train[:3])\n",
    "\n",
    "y_train = list(y_train)\n",
    "y_val = list(y_val)\n",
    "print(y_train[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h2>Beispiel Bilder</h2>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "nobs = 8 # Maximum number of images to display\n",
    "ncols = 4 # Number of columns in display\n",
    "nrows = nobs//ncols # Number of rows in display\n",
    "\n",
    "style.use(\"default\")\n",
    "plt.figure(figsize=(12,4*nrows))\n",
    "for i in range(nrows*ncols):\n",
    "    ax = plt.subplot(nrows, ncols, i+1)\n",
    "    plt.imshow(Image.open(X_train[i]))\n",
    "    plt.title(y_train[i], size=10)\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    " <h2> Genre Encoding</h2>\n",
    " <p style=\"font-size:20px\">\n",
    " Das neuronale Netz soll nach dem klassifizieren uns für jedes Genre eine Wahrscheinlichkeit ausgeben. <br>\n",
    " Daher müssen wir zu jedem Film Speichern, ob es in einem Genre ist oder nicht.\n",
    " <br><br>\n",
    " <table>\n",
    "    <tr>\n",
    "        <th>Film</th>\n",
    "        <th>Action</th>\n",
    "        <th>Comedy</th>\n",
    "        <th>Drama</th>\n",
    "        <th>Adventure</th>\n",
    "        <th>Crime</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>The Shadow</td>\n",
    "        <td>1</td>\n",
    "        <td>0</td>\n",
    "        <td>0</td>\n",
    "        <td>1</td>\n",
    "        <td>1</td>\n",
    "    </tr>\n",
    "</table>\n",
    " </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Fit the multi-label binarizer on the training set\n",
    "print(\"Labels:\")\n",
    "mlb = MultiLabelBinarizer()\n",
    "mlb.fit(y_train)\n",
    "\n",
    "# Loop over all labels and show them\n",
    "N_LABELS = len(mlb.classes_)\n",
    "for (i, label) in enumerate(mlb.classes_):\n",
    "    print(\"{}. {}\".format(i, label))\n",
    "\n",
    "# transform the targets of the training and test sets\n",
    "y_train_bin = mlb.transform(y_train)\n",
    "y_val_bin = mlb.transform(y_val)\n",
    "\n",
    "# Print example of movie posters and their binary targets\n",
    "for i in range(3):\n",
    "    print(X_train[i], y_train_bin[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Aufbau des neuronalen Netzes</h1>\n",
    "\n",
    "<div style=\"font-size:20px\">\n",
    "    <ol>\n",
    "    <li>Grundlagen</li>\n",
    "    <li>Parameter des neuronale Netzes festlegen</li>\n",
    "    <li>Modell bauen</li>\n",
    "    <li>Training</li>\n",
    "    <li>Validierung</li>\n",
    "    </ol>\n",
    "</div>\n",
    "\n",
    "<h3>Grundlagen</h3>\n",
    "<div style=\"font-size:18px\">\n",
    "    <p>Ein <em>künstliches neuronales Netz</em> besteht aus Schichten künstlicher Neuronen, welche miteinander eine Eingabe verarbeiten und eine Ausgabe erzeugen können. Moderne künstliche neuronale Netze bestehen aus einer Vielzahl an Ebenen, welche alle bestimmte Funktionen erfüllen. Besonders prominent in der Bildklassifizierung sind <strong>Convolutional Neural Networks (CNN)</strong>, welche im Kern aus Convolutional Layers bestehen.</p>\n",
    "    <figure style=\"text-align: center\">\n",
    "    <img src=\"./vortrag/typical_cnn.png\" alt=\"Typical CNN\" width=\"40%\">\n",
    "    <figcaption>Aufbau eines CNN [5]</figcaption>\n",
    "    </figure>\n",
    "    <h4>Convolutional Layer</h4>\n",
    "    <p><em>Convolutional Layers</em> können mit Bildfiltern verglichen werden: Sie sind Matrizen, die über das Eingangsbild gelegt werden und mit einer Matrixkonvolution eine neue Matrix generieren können. Diese generierten Matrizen stellen Merkmale des Eingangsbildes dar, wie bspw. Kanten, Tiefen, Formen etc. Werden mehrere solcher Merkmale verwendet, kann ein künstliches neuronales Netz eine Verknüpfung zu dem Label des Bildes herstellen. <br><br> <a href=\"https://deeplizard.com/resource/pavq7noze2\">Veranschaulichung von Filtern</a></p>\n",
    "    <figure style=\"text-align: center\">\n",
    "    <img src=\"./vortrag/feature_maps.png\" alt=\"Feature maps example\" width=\"40%\">\n",
    "    <figcaption>Beispiel einer Feature Map [4]</figcaption>\n",
    "    </figure>\n",
    "    <h4>Aktivierungsfunktion</h4>\n",
    "    Eine Aktivierungsfunktion transformiert verschiedene Eingabewerte auf Ausgabewerte. Eine oft verwendete Aktivierungsfunktion ist die <em>Rectified Linear Unit (ReLu)</em> Funktion, welche negative Werte neutralisiert und positive Werte beibehält</p>\n",
    "    <figure style=\"text-align: center\">\n",
    "    <img src=\"./vortrag/relu.svg\" alt=\"ReLu Funktion\" width=\"40%\">\n",
    "    <figcaption>Rectified Linear Unit (ReLu) Funktion [6]</figcaption>\n",
    "    </figure>\n",
    "    <h4>MaxPooling Layer</h4>\n",
    "    <p>Neben <em>Convolutional Layers</em> gibt es weitere Ebenen, wie dem MaxPooling. Diese unterstützen die Merkmalsextraktion, indem sie die herausgearbeiteten Merkmale verdeutlichen. Dabei können jedoch andere, möglicherweise weniger wichtige, Informationen verloren gehen. <br><br> <a href=\"https://deeplizard.com/resource/pavq7noze3\">Veranschaulichung von MaxPooling Layern</a> </p>\n",
    "    <h4>Dense Layer</h4>\n",
    "    <p> <em>Dense Layer</em> (Fully-Connected-Layer) verbinden alle Neuronen mit allen Inputs und Outputs. Jeder der Verbindungen besitzt dabei ein Gewicht. Die Inputs werden mit der Gewichtung multipliziert und aktivieren dadurch manch andere Neuroen. Diese Neuronen erhalten wiederum gewichte. Ob ein Neuron aktiviert wird hängt wieder von dem Ergebniss einer Aktivierungsfunktion ab.\n",
    "    <figure style=\"text-align: center\">\n",
    "    <img src=\"./vortrag/activation.png\" alt=\"Typical CNN\" width=\"40%\">\n",
    "    <figcaption>Berechnung eines Neurons</figcaption>\n",
    "    </figure>\n",
    "    <p>Am Ausgang eines jeden künstlichen neuronalen Netzes sitzt eine Ebene, dessen Neuronenzahl der Anzahl an Labels entspricht. Auch hier wird eine Aktivierungsfunktion verwendet, allerdings eine, die die Zuordnung der vorherigen Werte zu einem Label ermöglichen, bpsw. anhand einer Wahrscheinlichkeit.</p>\n",
    "    <h4>Dropout</h4>\n",
    "    <p> Das Dropout Layer sorgt dafür, dass eine definierte Menge an Neuronen, die ausgeschaltet werden und von nachfolgenden Ebenen nicht berücksichtigt werden.</p>\n",
    "    <h4>Batchnormalisation</h4>\n",
    "    <p>Dieser Layer Normalisiert den Output eines Neurons während eines Batches. Verhindert besonders \"starke\" Neuronen, die den Traininsgprozess dominieren könnten</p>\n",
    "    <h4>Metriken: Loss & Accuracy</h4>\n",
    "    <p>Für das Training eines künstlichen neuronalen Netzes werden Metriken eingesetzt, die die Qualität des Netzes beschreiben. Loss beschreibt hierbei die Abweichung des ausgegebenen Labels vom künstlichen neuronalen Netzes von dem eigentlichen Label. Es beschreibt also, wie fehlerbehaftet das Netz arbeitet. Accuracy beschreibt, wie hoch der Anteil der richtig klassifizierten Daten im Vergleich zu allen Klassifizierungen ist.</p>\n",
    "</div>\n",
    "\n",
    "<div style=\" display: flex; \n",
    "    justify-content: center; \n",
    "    align-items: center;\">\n",
    "<img src=\"./vortrag/cnn.png\" alt=\"Aufagbe\" width=\"1000\" height=\"500\"  title=\"\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h2>Parameter fürs das neuronale Netz festelegen</h2>\n",
    "<div style=\"font-size:18px\">\n",
    "IMG_SIZE = Die Breite und Höhe des Bildes. Bestimmt mit den Channels die Anzahl der Inputneuronen. (IMG_SIZE * IMG_SIZE * CHANNELS)\n",
    "<br>\n",
    "<br>\n",
    "CHANNELS = Gibt an, welches Farbschema unsere Daten haben z. B. 1 = Graustufen & 3 = RGB\n",
    "<br>\n",
    "<br>\n",
    "BATCHSIZE = Anzahl an Film Poster die unser neuronales Netz beim training versucht zu Klassifizieren, bevor die Gewichte angepasst werden.\n",
    "<br>\n",
    "<br>\n",
    "LEARNING_RATE = Die Learning Rate gibt an wie schnell unser neuronales Netz lernt. \n",
    "<br>\n",
    "<br>\n",
    "EPOCHES = Anzahl der Trainingsdurchläufe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 224 # Height and Width of an Image\n",
    "CHANNELS = 3 # 3 Stands for RGB\n",
    "# 224*224*3\n",
    "\n",
    "BATCH_SIZE = 50 # Number of learning repetitions\n",
    "SHUFFLE_BUFFER_SIZE = 1024 # Shuffle the training data by a chunck of 1024 observations\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE # Adapt preprocessing and prefetching dynamically\n",
    "TRAINABLE = True\n",
    "\n",
    "LEARNING_RATE = 9e-3\n",
    "EPOCHS = 30\n",
    "model_name=\"mobilenet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential(\n",
    "    [\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(0.4),\n",
    "        layers.RandomZoom(0.4),\n",
    "    ]\n",
    ")\n",
    "\n",
    "def parse_function(filename, label):\n",
    "    # Read an image from a file\n",
    "    image_string = tf.io.read_file(filename)\n",
    "    # Decode it into a dense vector\n",
    "    image_decoded = tf.image.decode_jpeg(image_string, channels=CHANNELS)\n",
    "    # Resize it to fixed shape\n",
    "    image_resized = tf.image.resize(image_decoded, [IMG_SIZE, IMG_SIZE])\n",
    "    # Normalize it from [0, 255] to [0.0, 1.0]\n",
    "    image_normalized = image_resized / 255.0\n",
    "    return image_normalized, label\n",
    "\n",
    "def create_dataset(filenames, labels, is_training=True, augment=False):\n",
    "    # Create a first dataset of file paths and labels\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\n",
    "    # Parse and preprocess observations in parallel\n",
    "    dataset = dataset.map(parse_function, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "    if is_training == True:\n",
    "        # This is a small dataset, only load it once, and keep it in memory.\n",
    "        dataset = dataset.cache()\n",
    "        # Shuffle the data each buffer size\n",
    "        dataset = dataset.shuffle(buffer_size=SHUFFLE_BUFFER_SIZE)\n",
    "\n",
    "    # Batch the data for multiple steps\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    if augment:\n",
    "        dataset = dataset.map(lambda x, y: (data_augmentation(x), y))\n",
    "    # Fetch batches in the background while the model is training.\n",
    "    dataset = dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "train_ds = create_dataset(X_train, y_train_bin, augment=True)\n",
    "val_ds = create_dataset(X_val, y_val_bin)\n",
    "\n",
    "for f, l in train_ds.take(1):\n",
    "    print(\"Shape of features array:\", f.numpy().shape)\n",
    "    print(\"Shape of labels array:\", l.numpy().shape)\n",
    "print(f\"Length of train data: {len(train_ds)}\")\n",
    "print(f\"Length of val data: {len(val_ds)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Vortrainiertes Modell herunterladen</h2>\n",
    "<div style=\"font-size:18px\">\n",
    "Mobilenet bietet viele verschiedene vortrainierte neuronale Netze an. Diese können bereits verschiedene Objekte erkennen.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor_url = \"https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4\"\n",
    "feature_extractor_layer = hub.KerasLayer(feature_extractor_url,\n",
    "                                         input_shape=(IMG_SIZE,IMG_SIZE,CHANNELS))\n",
    "                                         #mobilenet vorstellen\n",
    "feature_extractor_layer.trainable = TRAINABLE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Model zusammenbauen</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "        feature_extractor_layer,\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.6),\n",
    "        layers.Dense(1024, activation='relu'),\n",
    "        layers.Dense(N_LABELS, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h2> Parameter speichern (fürs Training & Testen )</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"./data/models/{model_name}.txt\",'w') as fh:\n",
    "    fh.write(f'BATCH_SIZE = {str(BATCH_SIZE)} \\n')\n",
    "    fh.write(f'EPOCHS = {str(EPOCHS)} \\n')\n",
    "    fh.write(f'LEARNING_RATE = {str(LEARNING_RATE)} \\n')\n",
    "    fh.write(f'TRAINABLE = {str(TRAINABLE)} \\n')\n",
    "    model.summary(print_fn=lambda x: fh.write(x + '\\n'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h2>Model Trainieren</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(LEARNING_RATE)\n",
    "loss = tf.keras.metrics.binary_crossentropy\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=loss,\n",
    "    metrics=[\"accuracy\"])\n",
    "\n",
    "start = time()\n",
    "history = model.fit(train_ds,epochs=EPOCHS,validation_data=create_dataset(X_val, y_val_bin))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Graphische Veranschaulichung wie gut unser Model gelernt hat</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, EPOCHS), history.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, EPOCHS), history.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, EPOCHS), history.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, EPOCHS), history.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "\n",
    "plt.title(\"Training loss and accuracy on genre classification\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(f\"./data/models/{model_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Sichern des trainierten Models</h2>\n",
    "<p style=\"font-size:18px\">\n",
    "Sicher des tranierten Models, um dieses benutzen zu können wenn Filmposter klassifizieren möchten.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"./data/models\"\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "model.save(f\"{model_dir}/{model_name}.h5\",save_format=\"h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Demo</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Verschiedene Film Poster vorbereiten</h2>\n",
    "<div style=\"font-size:18px\"> Filmposter die das Model noch nicht kennengelernt hat werden hier vorbereiten, damit diese klassifiziert werden können\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_user_images(filename, label, movie_name):\n",
    "    image_string = tf.io.read_file(filename)\n",
    "    image_decoded = tf.image.decode_jpeg(image_string, channels=CHANNELS)\n",
    "    image_resized = tf.image.resize(image_decoded, [IMG_SIZE, IMG_SIZE])\n",
    "    image_normalized = image_resized / 255.0\n",
    "    image_normalized = np.expand_dims(image_normalized, axis=0)\n",
    "    return image_normalized, label, movie_name\n",
    "\n",
    "\n",
    "example_filenames_labels = [\n",
    "    {\n",
    "        \"file\": \"./data/validationImages/Avengers-Action-Science-Fiction.jpg\",\n",
    "        \"labels\": [\"Action\", \"Science-Fiction\", \"Abenteuer\"],\n",
    "        \"name\": \"Avengers\"\n",
    "    },\n",
    "    {\n",
    "        \"file\": \"./data/validationImages/crazyStupidLove-Romanze-Komödie.jpg\",\n",
    "        \"labels\": [\"Romanze\", \"Komödie\", \"Drama\"],\n",
    "        \"name\":\"Crazy Stupid Love\"\n",
    "    },\n",
    "    {\n",
    "        \"file\": \"./data/validationImages/matrix_action_scifi_abenteuer_fantasy.jpeg\",\n",
    "        \"labels\": [\"Fantasy\", \"Action\", \"Science-Fiction\", \"Abenteuer\"],\n",
    "        \"name\":\"Matrix\"\n",
    "    },\n",
    "    {\n",
    "        \"file\": \"./data/validationImages/batman_action_thriller_drama_abendteuer_.jpg\",\n",
    "        \"labels\": [\"Action\", \"Thriller\", \"Drama\", \"Abenteuer\", \"Krimi\", \"Mystery\"],\n",
    "        \"name\":\"Batman the dark knight\"\n",
    "    }\n",
    "]\n",
    "movies_to_predict = []\n",
    "for movie in example_filenames_labels:\n",
    "    movies_to_predict.append(prepare_user_images(\n",
    "        movie[\"file\"], movie[\"labels\"], movie[\"name\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Poster Klassifizieren lassen</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = \"mobilenet_less_drama_batchnorm_0-7dropout_augmentation_shorter_slower\"\n",
    "has_custom_layer = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'--------------Avengers------------------'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 874ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Prediction: ['Action']\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"Actual: ['Action', 'Science-Fiction', 'Abenteuer']\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'--------------Crazy Stupid Love------------------'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 63ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Prediction: ['Comedy', 'Drama', 'Romance']\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"Actual: ['Romanze', 'Komödie']\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'--------------Matrix------------------'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 54ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Prediction: ['Action', 'Crime']\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"Actual: ['Fantasy', 'Action', 'Science-Fiction', 'Abenteuer']\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'--------------Batman the dark knight------------------'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 50ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Prediction: ['Crime', 'Thriller']\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"Actual: ['Action', 'Thriller', 'Drama', 'Abenteuer', 'Krimi', 'Mystery']\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(\n",
    "    f\"./data/models/{final_model}.h5\", custom_objects={\"KerasLayer\": feature_extractor_layer})\n",
    "\n",
    "\n",
    "for file, labels, name in movies_to_predict:\n",
    "    display(\"--------------\" + name + \"------------------\")\n",
    "    prediction = (model.predict(file) > 0.5).astype('int')\n",
    "    prediction = pd.Series(prediction[0])\n",
    "    prediction.index = mlb.classes_\n",
    "    prediction = prediction[prediction == 1].index.values\n",
    "\n",
    "    display(\"Prediction: \" + str(list(prediction)))\n",
    "    display(\"Actual: \" + str(list(labels)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Quellen</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://projectbase.medien.hs-duesseldorf.de/eild.nrw-module/lernmodul-bilder\n",
    "- https://deeplizard.com/\n",
    "- https://github.com/ashrefm/multi-label-soft-f1\n",
    "- [4] https://tex.stackexchange.com/questions/91566/syntax-similar-to-centering-for-right-and-left\n",
    "- [5] Aphex34, CC BY-SA 4.0 <https://creativecommons.org/licenses/by-sa/4.0>, via Wikimedia Commons\n",
    "- [6] Laughsinthestocks, CC BY-SA 4.0 <https://creativecommons.org/licenses/by-sa/4.0>, via Wikimedia Commons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1aa311f504caac0f188f78406e816835344f2fcf8805d2b336528ed71bf52c28"
  },
  "kernelspec": {
   "display_name": "Python 3.9.8 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
